[[algorithms-knn]]
= K-Nearest Neighbors
:description: This section describes the K-Nearest Neighbors (KNN) algorithm in the Neo4j Graph Data Science library.

:entity: relationship
:result: similarity score
:algorithm: K-Nearest Neighbors
:knnSpecificConfigurationTableTitle: Algorithm specific configuration

include::partial$/algorithms/shared/algorithm-traits.adoc[]

{nbsp} +
[TIP]
====
kNN is featured in the end-to-end example Jupyter notebooks:

* https://neo4j.com/docs/graph-data-science-client/current/tutorials/fastrp-and-knn/[Product recommendations with kNN based on FastRP embeddings]
====

[[algorithms-knn-intro]]
== Introduction

The K-Nearest Neighbors algorithm computes a distance value for all node pairs in the graph and creates new relationships between each node and its k nearest neighbors.
The distance is calculated based on node properties.

The input of this algorithm is a homogeneous graph.
The graph does not need to be connected, in fact, existing relationships between nodes will be ignored - apart from random walk sampling if that that initial sampling option is used.
New relationships are created between each node and its k nearest neighbors.

The K-Nearest Neighbors algorithm compares given properties of each node.
The `k` nodes where these properties are most similar are the k-nearest neighbors.

The initial set of neighbors is picked at random and verified and refined in multiple iterations.
The number of iterations is limited by the configuration parameter `maxIterations`.
The algorithm may stop earlier if the neighbor lists only change by a small amount, which can be controlled by the configuration parameter `deltaThreshold`.

The particular implementation is based on https://dl.acm.org/doi/abs/10.1145/1963405.1963487[Efficient k-nearest neighbor graph construction for generic similarity measures] by Wei Dong et al.
Instead of comparing every node with every other node, the algorithm selects possible neighbors based on the assumption, that the neighbors-of-neighbors of a node are most likely already the nearest one.
The algorithm scales quasi-linear with respect to the node count, instead of being quadratic.

Furthermore, the algorithm only compares a sample of all possible neighbors on each iteration, assuming that eventually all possible neighbors will be seen.
This can be controlled with the configuration parameter `sampleRate`:

* A valid sample rate must be in between 0 (exclusive) and 1 (inclusive).
* The default value is `0.5`.
* The parameter is used to control the trade-off between accuracy and runtime-performance.
* A higher sample rate will increase the accuracy of the result.
** The algorithm will also require more memory and will take longer to compute.
* A lower sample rate will increase the runtime-performance.
** Some potential nodes may be missed in the comparison and may not be included in the result.

When encountered neighbors have equal similarity to the least similar already known neighbor, randomly selecting which node to keep can reduce the risk of some neighborhoods not being explored.
This behavior is controlled by the configuration parameter `perturbationRate`.

The output of the algorithm are new relationships between nodes and their k-nearest neighbors.
Similarity scores are expressed via relationship properties.

For more information on this algorithm, see:

* https://dl.acm.org/doi/abs/10.1145/1963405.1963487[Efficient k-nearest neighbor graph construction for generic similarity measures]
* https://en.wikipedia.org/wiki/Nearest_neighbor_graph[Nearest neighbor graph (Wikipedia)]

It is also possible to apply filtering on the source and/or target nodes in the produced similarity pairs. You can consider the xref:algorithms/filtered-knn.adoc[filtered K-Nearest Neighbors] algorithm for this purpose.

[NOTE]
====
Running this algorithm requires sufficient available memory.
Before running this algorithm, we recommend that you read xref:common-usage/memory-estimation.adoc[Memory Estimation].
====


[[algorithms-knn-introduction-metrics]]
=== Similarity metrics

The similarity measure used in the KNN algorithm depends on the type of the configured node properties.
KNN supports both scalar numeric values and lists of numbers.


==== Scalar numbers

When a property is a scalar number, the similarity is computed as follows:

image::equations/knn-scalar-similarity.svg[title="one divided by one plus the absolute difference", float="center"]

This gives us a number in the range `(0, 1]`.


==== List of integers

When a property is a list of integers, similarity can be measured with either the Jaccard similarity or the Overlap coefficient.

Jaccard similarity::
+
image::knn-formulas/jacard.svg[title="size of intersection divided by size of union", float="center"]


Overlap coefficient::
+
image::knn-formulas/overlap.svg[title="size of intersection divided by size of minimum set", float="center"]

Both of these metrics give a score in the range `[0, 1]` and no normalization needs to be performed.
Jaccard similarity is used as the default option for comparing lists of integers when the metric is not specified.


==== List of floating-point numbers

When a property is a list of floating-point numbers, there are three alternatives for computing similarity between two nodes.

The default metric used is that of Cosine similarity.

Cosine similarity::
+
image::knn-formulas/cosine.svg[title="dot product of the vectors divided by the product of their lengths", float="center"]

Notice that the above formula gives a score in the range of `[-1, 1]` .
The score is normalized into the range `[0, 1]` by doing `score = (score + 1) / 2`.

The other two metrics include the Pearson correlation score and Normalized Euclidean similarity.


Pearson correlation score::
+
image::knn-formulas/pearson.svg[title="covariance divided by the product of the standard deviations", float="center"]

As above, the formula gives a score in the range `[-1, 1]`, which is normalized into the range `[0, 1]` similarly.


Euclidean similarity::
+
image::knn-formulas/ed.svg[title="the root of the sum of the square difference between each pair of elements", float="center"]

The result from this formula is a non-negative value, but is not necessarily bounded into the  `[0, 1]` range.
Î¤o bound the number into this range and obtain a similarity score, we return `score = 1 / (1 + distance)`, i.e., we perform the same normalization as in the case of scalar values.


==== Multiple properties

Finally, when multiple properties are specified, the similarity of the two neighbors is the mean of the similarities of the individual properties, i.e. the simple mean of the numbers, each of which is in the range `[0, 1]`, giving a total score also in the `[0, 1]` range.

[NOTE]
====
The validity of this mean is highly context dependent, so take care when applying it to your data domain.
====

[[algorithms-knn-node-properties-configuration]]
==== Node properties and metrics configuration

The node properties and metrics to use are specified with the `nodeProperties` configuration parameter.
At least one node property must be specified.

This parameter accepts one of:

.nodeProperties syntax
[cols="1,2a"]
|===
| a single property name
| `nodeProperties: 'embedding'`
| a Map of property keys to metrics
|
----
nodeProperties: {
    embedding: 'COSINE',
    age: 'DEFAULT',
    lotteryNumbers: 'OVERLAP'
}
----
| list of Strings and/or Maps
|
----
nodeProperties: [
    {embedding: 'COSINE'},
    'age',
    {lotteryNumbers: 'OVERLAP'}
]
----
|===

The available metrics by type are:

.Available metrics by type
[options=header,cols="1,1"]
|===
| type            | metric
| List of Integer | `JACCARD`, `OVERLAP`
| List of Float   | `COSINE`, `EUCLIDEAN`, `PEARSON`
|===

For any property type, `DEFAULT` can also be specified to use the default metric.
For scalar numbers, there is only the default metric.


[[algorithms-knn-introduction-sampling]]
=== Initial neighbor sampling

The algorithm starts off by picking `k` random neighbors for each node.
There are two options for how this random sampling can be done.

Uniform::

The first `k` neighbors for each node are chosen uniformly at random from all other nodes in the graph.
This is the classic way of doing the initial sampling.
It is also the algorithm's default.
Note that this method does not actually use the topology of the input graph.

Random Walk::

From each node we take a depth biased random walk and choose the first `k` unique nodes we visit on that walk as our initial random neighbors.
If after some internally defined `O(k)` number of steps a random walk, `k` unique neighbors have not been visited, we will fill in the remaining neighbors using the uniform method described above.
The random walk method makes use of the input graph's topology and may be suitable if it is more likely to find good similarity scores between topologically close nodes.

[NOTE]
====
The random walk used is biased towards depth in the sense that it will more likely choose to go further away from its previously visited node, rather that go back to it or to a node equidistant to it.
The intuition of this bias is that subsequent iterations of comparing neighbor-of-neighbors will likely cover the extended (topological) neighborhood of each node.
====


[[algorithms-knn-syntax]]
== Syntax

include::partial$/algorithms/shared/syntax-intro-named-graph.adoc[]

.K-Nearest Neighbors syntax per mode
[.tabbed-example, caption = ]
====

[.include-with-stream]
======
.Run K-Nearest Neighbors in stream mode on a named graph.
[source, cypher, role=noplay]
----
CALL gds.knn.stream(
  graphName: String,
  configuration: Map
) YIELD
  node1: Integer,
  node2: Integer,
  similarity: Float
----

include::partial$/algorithms/common-configuration/common-parameters.adoc[]

.General configuration for algorithm execution on a named graph.
[opts="header",cols="3,2,3m,2,8"]
|===
| Name          | Type   | Default | Optional | Description
include::partial$/algorithms/common-configuration/common-stream-stats-configuration-entries.adoc[]
|===

include::partial$/algorithms/knn/knn-specific-algo-config.adoc[]

.Results
[opts="header",cols="1m,1,6"]
|===
| Name       | Type    | Description
| node1      | Integer | Node ID of the first node.
| node2      | Integer | Node ID of the second node.
| similarity | Float   | Similarity score for the two nodes.
|===
======

[.include-with-stats]
======
.Run K-Nearest Neighbors in stats mode on a named graph.
[source, cypher, role=noplay]
----
CALL gds.knn.stats(
  graphName: String,
  configuration: Map
)
YIELD
  preProcessingMillis: Integer,
  computeMillis: Integer,
  postProcessingMillis: Integer,
  nodesCompared: Integer,
  ranIterations: Integer,
  didConverge: Boolean,
  nodePairsConsidered: Integer,
  similarityPairs: Integer,
  similarityDistribution: Map,
  configuration: Map
----

include::partial$/algorithms/common-configuration/common-parameters.adoc[]

.General configuration for algorithm execution on a named graph.
[opts="header",cols="3,2,3m,2,8"]
|===
| Name          | Type   | Default | Optional | Description
include::partial$/algorithms/common-configuration/common-stream-stats-configuration-entries.adoc[]
|===

include::partial$/algorithms/knn/knn-specific-algo-config.adoc[]

.Results
[opts="header",cols="1,1,6"]
|===
| Name                          | Type      | Description
| ranIterations                 | Integer   | Number of iterations run.
| didConverge                   | Boolean   | Indicates if the algorithm converged.
| nodePairsConsidered           | Integer   | The number of similarity computations.
| preProcessingMillis           | Integer   | Milliseconds for preprocessing the data.
| computeMillis                 | Integer   | Milliseconds for running the algorithm.
| postProcessingMillis          | Integer   | Milliseconds for computing similarity value distribution statistics.
| nodesCompared                 | Integer   | The number of nodes for which similarity was computed.
| similarityPairs               | Integer   | The number of similarities in the result.
| similarityDistribution        | Map       | Map containing min, max, mean as well as p50, p75, p90, p95, p99 and p999 percentile values of the computed similarity results.
| configuration                 | Map       | The configuration used for running the algorithm.
|===
======

[.include-with-mutate]
======
.Run K-Nearest Neighbors in mutate mode on a graph stored in the catalog.
[source, cypher, role=noplay]
----
CALL gds.knn.mutate(
  graphName: String,
  configuration: Map
)
YIELD
  preProcessingMillis: Integer,
  computeMillis: Integer,
  mutateMillis: Integer,
  postProcessingMillis: Integer,
  relationshipsWritten: Integer,
  nodesCompared: Integer,
  ranIterations: Integer,
  didConverge: Boolean,
  nodePairsConsidered: Integer,
  similarityDistribution: Map,
  configuration: Map
----

include::partial$/algorithms/common-configuration/common-parameters.adoc[]

.General configuration for algorithm execution on a named graph.
[opts="header",cols="3,2,3m,2,8"]
|===
| Name          | Type   | Default | Optional | Description
include::partial$/algorithms/common-configuration/common-mutate-configuration-entries.adoc[]
|===

include::partial$/algorithms/knn/knn-specific-algo-config.adoc[]

.Results
[opts="header",cols="1,1,6"]
|===
| Name                   | Type    | Description
| ranIterations          | Integer | Number of iterations run.
| didConverge            | Boolean | Indicates if the algorithm converged.
| nodePairsConsidered    | Integer | The number of similarity computations.
| preProcessingMillis    | Integer | Milliseconds for preprocessing the data.
| computeMillis          | Integer | Milliseconds for running the algorithm.
| mutateMillis           | Integer | Milliseconds for adding properties to the projected graph.
| postProcessingMillis   | Integer | Milliseconds for computing similarity value distribution statistics.
| nodesCompared          | Integer | The number of nodes for which similarity was computed.
| relationshipsWritten   | Integer | The number of relationships created.
| similarityDistribution | Map     | Map containing min, max, mean, stdDev and p1, p5, p10, p25, p75, p90, p95, p99, p100 percentile values of the computed similarity results.
| configuration          | Map     | The configuration used for running the algorithm.
|===
======

[.include-with-write]
======
.Run K-Nearest Neighbors in write mode on a graph stored in the catalog.
[source, cypher, role=noplay]
----
CALL gds.knn.write(
  graphName: String,
  configuration: Map
)
YIELD
  preProcessingMillis: Integer,
  computeMillis: Integer,
  writeMillis: Integer,
  postProcessingMillis: Integer,
  nodesCompared: Integer,
  ranIterations: Integer,
  didConverge: Boolean,
  nodePairsConsidered: Integer,
  relationshipsWritten: Integer,
  similarityDistribution: Map,
  configuration: Map
----

include::partial$/algorithms/common-configuration/common-parameters.adoc[]

.General configuration for algorithm execution on a named graph.
[opts="header",cols="3,2,3m,2,8"]
|===
| Name          | Type   | Default | Optional | Description
include::partial$/algorithms/common-configuration/common-write-configuration-entries.adoc[]
|===

include::partial$/algorithms/knn/knn-specific-algo-config.adoc[]

.Results
[opts="header",cols="1,1,6"]
|===
| Name                   | Type    | Description
| ranIterations          | Integer | Number of iterations run.
| didConverge            | Boolean | Indicates if the algorithm converged.
| nodePairsConsidered    | Integer | The number of similarity computations.
| preProcessingMillis    | Integer | Milliseconds for preprocessing the data.
| computeMillis          | Integer | Milliseconds for running the algorithm.
| writeMillis            | Integer | Milliseconds for writing result data back to Neo4j.
| postProcessingMillis   | Integer | Milliseconds for computing similarity value distribution statistics.
| nodesCompared          | Integer | The number of nodes for which similarity was computed.
| relationshipsWritten   | Integer | The number of relationships created.
| similarityDistribution | Map     | Map containing min, max, mean, stdDev and p1, p5, p10, p25, p75, p90, p95, p99, p100 percentile values of the computed similarity results.
| configuration          | Map     | The configuration used for running the algorithm.
|===
======
====


[NOTE]
====
The KNN algorithm does not read any relationships, but the values for `relationshipProjection` or `relationshipQuery` are still being used and respected for the graph loading.
====

The results are the same as running write mode on a named graph, see xref:algorithms/knn.adoc#algorithms-knn-syntax[write mode syntax above].

[NOTE]
====
To get a deterministic result when running the algorithm:

* the `concurrency` parameter must be set to one
* the `randomSeed` must be explicitly set.
====

[[algorithms-knn-examples]]
== Examples

In this section we will show examples of running the KNN algorithm on a concrete graph.
With the _Uniform sampler_, KNN samples initial neighbors uniformly at random, and doesn't take into account graph topology.
This means KNN can run on a graph of only nodes, without any relationships.
Consider the following graph of five disconnected Person nodes.


image::example-graphs/knn.svg[Visualization of the example graph,align="center"]

[source, cypher, role=noplay setup-query]
----
CREATE (alice:Person {name: 'Alice', age: 24, lotteryNumbers: [1, 3], embedding: [1.0, 3.0]})
CREATE (bob:Person {name: 'Bob', age: 73, lotteryNumbers: [1, 2, 3], embedding: [2.1, 1.6]})
CREATE (carol:Person {name: 'Carol', age: 24, lotteryNumbers: [3], embedding: [1.5, 3.1]})
CREATE (dave:Person {name: 'Dave', age: 48, lotteryNumbers: [2, 4], embedding: [0.6, 0.2]})
CREATE (eve:Person {name: 'Eve', age: 67, lotteryNumbers: [1, 5], embedding: [1.8, 2.7]});
----

In the example, we want to use the K-Nearest Neighbors algorithm to compare people based on either their age or a combination on all provided properties.

include::partial$/algorithms/shared/examples-named-native-note.adoc[]

.The following statement will project the graph and store it in the graph catalog.
[source,cypher,role=noplay graph-project-query]
----
CALL gds.graph.project(
    'myGraph',
    {
        Person: {
            properties: ['age','lotteryNumbers','embedding']
        }
    },
    '*'
);
----


[[algorithms-knn-examples-memory-estimation]]
=== Memory Estimation

:mode: write
include::partial$/algorithms/shared/examples-estimate-intro.adoc[]

[role=query-example]
--
.The following will estimate the memory requirements for running the algorithm:
[source, cypher, role=noplay]
----
CALL gds.knn.write.estimate('myGraph', {
  nodeProperties: ['age'],
  writeRelationshipType: 'SIMILAR',
  writeProperty: 'score',
  topK: 1
})
YIELD nodeCount, bytesMin, bytesMax, requiredMemory
----

.Results
[opts="header", cols="1,1,1,1"]
|===
| nodeCount | bytesMin | bytesMax | requiredMemory
| 5         | 2096     | 3152     | "[2096 Bytes \... 3152 Bytes]"
|===
--


[[algorithms-knn-examples-stream]]
=== Stream

include::partial$/algorithms/shared/examples-stream-intro.adoc[]

[role=query-example]
--
.The following will run the algorithm, and stream results:
[source, cypher, role=noplay]
----
CALL gds.knn.stream('myGraph', {
    topK: 1,
    nodeProperties: ['age'],
    // The following parameters are set to produce a deterministic result
    randomSeed: 1337,
    concurrency: 1,
    sampleRate: 1.0,
    deltaThreshold: 0.0
})
YIELD node1, node2, similarity
RETURN gds.util.asNode(node1).name AS Person1, gds.util.asNode(node2).name AS Person2, similarity
ORDER BY similarity DESCENDING, Person1, Person2
----

.Results
[opts="header"]
|===
| Person1 | Person2 | similarity
| "Alice" | "Carol" | 1.0
| "Carol" | "Alice" | 1.0
| "Bob"   | "Eve"   | 0.14285714285714285
| "Eve"   | "Bob"   | 0.14285714285714285
| "Dave"  | "Eve"   | 0.05
|===
--

We use default values for the procedure configuration parameter for most parameters.
The `randomSeed` and `concurrency` is set to produce the same result on every invocation.
The `topK` parameter is set to 1 to only return the single nearest neighbor for every node.
Notice that the similarity between Dave and Eve is very low.
Setting the `similarityCutoff` parameter to 0.10 will filter the relationship between them, removing it from the result.

[[algorithms-knn-examples-stats]]
=== Stats

:stats-syntax: algorithms-knn-syntax
include::partial$/algorithms/shared/examples-stats-intro.adoc[]

[role=query-example]
--
.The following will run the algorithm and return the result in form of statistical and measurement values:
[source, cypher, role=noplay]
----
CALL gds.knn.stats('myGraph', {topK: 1, concurrency: 1, randomSeed: 42, nodeProperties: ['age']})
YIELD nodesCompared, similarityPairs
----

.Results
[opts="header",cols="2"]
|===
| nodesCompared | similarityPairs
| 5             | 5
|===
--


[[algorithms-knn-examples-mutate]]
=== Mutate

include::partial$/algorithms/shared/examples-mutate-intro.adoc[]

[role=query-example]
--
.The following will run the algorithm, and write back results to the in-memory graph:
[source, cypher, role=noplay]
----
CALL gds.knn.mutate('myGraph', {
    mutateRelationshipType: 'SIMILAR',
    mutateProperty: 'score',
    topK: 1,
    randomSeed: 42,
    concurrency: 1,
    nodeProperties: ['age']
})
YIELD nodesCompared, relationshipsWritten
----

.Results
[opts="header"]
|===
| nodesCompared | relationshipsWritten
| 5             | 5
|===
--

As we can see from the results, the number of created relationships is equal to the number of rows in the streaming example.

[NOTE]
====
The relationships that are produced by the mutation are always directed, even if the input graph is undirected.
If for example `a -> b` is topK for `a` and symmetrically `b -> a` is topK for `b`, it appears as though an undirected relationship is produced.
However, they are just two directed relationships that have been independently produced.
====


[[algorithms-knn-examples-write]]
=== Write

The `write` execution mode extends the `stats` mode with an important side effect: for each pair of nodes we create a relationship with the similarity score as a property to the Neo4j database.
The type of the new relationship is specified using the mandatory configuration parameter `writeRelationshipType`.
Each new relationship stores the similarity score between the two nodes it represents.
The relationship property key is set using the mandatory configuration parameter `writeProperty`.
The result is a single summary row, similar to `stats`, but with some additional metrics.

For more details on the `write` mode in general, see xref:common-usage/running-algos.adoc#running-algos-write[Write].


[role=query-example]
--
.The following will run the algorithm, and write back results:
[source, cypher, role=noplay]
----
CALL gds.knn.write('myGraph', {
    writeRelationshipType: 'SIMILAR',
    writeProperty: 'score',
    topK: 1,
    randomSeed: 42,
    concurrency: 1,
    nodeProperties: ['age']
})
YIELD nodesCompared, relationshipsWritten
----

.Results
[opts="header"]
|===
| nodesCompared | relationshipsWritten
| 5             | 5
|===
--

As we can see from the results, the number of created relationships is equal to the number of rows in the streaming example.

[NOTE]
====
The relationships that are written are always directed, even if the input graph is undirected.
If for example `a -> b` is topK for `a` and symmetrically `b -> a` is topK for `b`, it appears as though an undirected relationship is written.
However, they are just two directed relationships that have been independently written.
====

[[algorithms-knn-examples-multiple-properties]]
=== Calculation with multiple properties

If we want to calculate similarity based on multiple metrics, we can calculate the similarity for each property individually and take their mean.
As an example, we can use the Normalized Euclidean similarity metric for the embedding property and the Overlap metric for the lottery numbers property in addition to the age property.

[role=query-example]
--
.The following shows an example of using multiple properties to calculate similarity and streams the results:
[source, cypher, role=noplay]
----
CALL gds.knn.stream('myGraph', {
    topK: 1,
    nodeProperties: [
        {embedding: "EUCLIDEAN"},
        'age',
        {lotteryNumbers: "OVERLAP"}
    ],
    // The following parameters are set to produce a deterministic result
    randomSeed: 1337,
    concurrency: 1,
    sampleRate: 1.0,
    deltaThreshold: 0.0
})
YIELD node1, node2, similarity
RETURN gds.util.asNode(node1).name AS Person1, gds.util.asNode(node2).name AS Person2, similarity
ORDER BY similarity DESCENDING, Person1, Person2
----
.Results
[opts="header"]
|===
| Person1 | Person2 | similarity
| "Alice" | "Carol" | 0.931216931216931
| "Carol" | "Alice" | 0.931216931216931
| "Bob"   | "Carol" | 0.432336103416436
| "Eve"   | "Alice"   | 0.366920651602733
| "Dave"  | "Bob"   | 0.243466706038683
|===

Note that the two distinct maps in the query could be merged to a single one.
--
