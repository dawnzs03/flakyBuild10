[[machine-learning-training-methods-multilayer-perceptron]]
[.alpha]
= Multilayer Perceptron

include::partial$/operations-reference/alpha-note.adoc[]

A Multilayer Perceptron (MLP) is a type of feed-forward neural network. It consists of multiple layers of connected neurons. The value of a neuron is computed by applying an activation function on the aggregated weighted inputs from previous layer.
For classification, the size of the output layer is based on the number of classes. To optimize the weights of the network, GDS uses gradient descent with a Cross Entropy Loss.


include::partial$/machine-learning/training-methods/gradient-descent-config-tuning.adoc[leveloffset =+ 1]

include::partial$/machine-learning/training-methods/penalty-config-tuning.adoc[leveloffset =+ 1]


=== HiddenLayerSizes
This parameter defines the shape of the neural network. Each entry represents the number of neurons in a layer. The length of the list defines the number of hidden layers. Deeper and larger networks can theoretically approximate high degree surfaces better, at the expense of having more weights (and biases) that need to be trained.


include::partial$/machine-learning/training-methods/focus-weight-config-tuning.adoc[leveloffset =+ 1]
