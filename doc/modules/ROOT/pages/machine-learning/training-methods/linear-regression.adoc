[[machine-learning-training-methods-linear-regression]]
[.alpha]
= Linear regression

include::partial$/operations-reference/alpha-note.adoc[]

Linear regression is a fundamental supervised machine learning regression method.
This trains a model by minimizing a loss function which depends on a weight matrix and on the training data.
The loss can be minimized for example using gradient descent.
Neo4j Graph Data Science uses the Adam optimizer which is a gradient descent type algorithm.

The weights are in the form of a feature-sized vector `w` and a bias `b`.
The loss function is then defined as:

`MSE(wx + b)`

where `MSE` is the https://en.wikipedia.org/wiki/Mean_squared_error#Predictor[mean square error].

To avoid overfitting one may also add a https://en.wikipedia.org/wiki/Regularization_(mathematics)[regularization] term to the loss.
Neo4j Graph Data Science supports the option of `l2` regularization which can be configured using the `penalty` parameter.


include::partial$/machine-learning/training-methods/gradient-descent-config-tuning.adoc[leveloffset =+ 1]
